{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = {\n",
    "    \"name\": \"John\",\n",
    "    \"full_name\": \"John Doe\",\n",
    "    \"user_profile_background\": \"Senior software engineer leading a team of 5 developers\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_instructions = {\n",
    "    \"triage_rules\": {\n",
    "        \"ignore\": \"Marketing newsletters, spam emails, mass company announcements\",\n",
    "        \"notify\": \"Team member out sick, build system notifications, project status updates\",\n",
    "        \"respond\": \"Direct questions from team members, meeting requests, critical bug reports\",\n",
    "    },\n",
    "    \"agent_instructions\": \"Use these tools when appropriate to help manage John's tasks efficiently.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = {\n",
    "    \"from\": \"Alice Smith <alice.smith@company.com>\",\n",
    "    \"to\": \"John Doe <john.doe@company.com>\",\n",
    "    \"subject\": \"Quick question about API documentation\",\n",
    "    \"body\": \"\"\"\n",
    "Hi John,\n",
    "\n",
    "I was reviewing the API documentation for the new authentication service and noticed a few endpoints seem to be missing from the specs. Could you help clarify if this was intentional or if we should update the docs?\n",
    "\n",
    "Specifically, I'm looking at:\n",
    "- /auth/refresh\n",
    "- /auth/validate\n",
    "\n",
    "Thanks!\n",
    "Alice\"\"\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict, Literal, Annotated\n",
    "from langchain.chat_models import init_chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(model = \"MFDoom/deepseek-r1-tool-calling:8b\", model_provider = \"ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Router(BaseModel):\n",
    "    \"\"\"Analyze the unread email and route it according to its content.\"\"\"\n",
    "\n",
    "    reasoning: str = Field(\n",
    "        description=\"Step-by-step reasoning behind the classification.\"\n",
    "    )\n",
    "    classification: Literal[\"ignore\", \"respond\", \"notify\"] = Field(\n",
    "        description=\"The classification of an email: 'ignore' for irrelevant emails, \"\n",
    "        \"'notify' for important information that doesn't need a response, \"\n",
    "        \"'respond' for emails that need a reply\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_router = llm.with_structured_output(Router)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import triage_system_prompt, triage_user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def write_email(to: str, subject: str, content: str) -> str:\n",
    "    \"\"\"Write and send an email.\"\"\"\n",
    "    # Placeholder response - in real app would send email\n",
    "    return f\"Email sent to {to} with subject '{subject}'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def schedule_meeting(\n",
    "    attendees: list[str], \n",
    "    subject: str, \n",
    "    duration_minutes: int, \n",
    "    preferred_day: str\n",
    ") -> str:\n",
    "    \"\"\"Schedule a calendar meeting.\"\"\"\n",
    "    # Placeholder response - in real app would check calendar and schedule\n",
    "    return f\"Meeting '{subject}' scheduled for {preferred_day} with {len(attendees)} attendees\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def check_calendar_availability(day: str) -> str:\n",
    "    \"\"\"Check calendar availability for a given day.\"\"\"\n",
    "    # Placeholder response - in real app would check actual calendar\n",
    "    return f\"Available times on {day}: 9:00 AM, 2:00 PM, 4:00 PM\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define tools for managing memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "from langchain.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OON YEE SEM\\AppData\\Local\\Temp\\ipykernel_18152\\644661452.py:1: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  ollama_embedding = OllamaEmbeddings(model=\"mxbai-embed-large:latest\")\n",
      "C:\\Users\\OON YEE SEM\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langgraph\\store\\base\\embed.py:95: LangChainBetaWarning: The function `init_embeddings` is in beta. It is actively being worked on, so the API may change.\n",
      "  return init_embeddings(embed)\n"
     ]
    }
   ],
   "source": [
    "ollama_embedding = OllamaEmbeddings(model=\"mxbai-embed-large:latest\")\n",
    "\n",
    "store = InMemoryStore(\n",
    "    index = {\"embed\" : \"openai:text-embedding-3-small\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langmem import create_manage_memory_tool, create_search_memory_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "manage_memory_tool = create_manage_memory_tool(\n",
    "    namespace = (\n",
    "        \"email_assistant\",\n",
    "        \"{langgraph_user_id}\",\n",
    "        \"collection\"\n",
    " \n",
    "    )\n",
    ")\n",
    "search_memory_tool = create_search_memory_tool(\n",
    "    namespace = (\n",
    "        \"email_assistant\",\n",
    "        \"{langgraph_user_id}\",\n",
    "        \"collection\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_system_prompt_memory = \"\"\"\n",
    "< Role >\n",
    "You are {full_name}'s executive assistant. You are a top-notch executive assistant who cares about {name} performing as well as possible.\n",
    "</ Role >\n",
    "\n",
    "< Tools >\n",
    "You have access to the following tools to help manage {name}'s communications and schedule:\n",
    "\n",
    "1. write_email(to, subject, content) - Send emails to specified recipients\n",
    "2. schedule_meeting(attendees, subject, duration_minutes, preferred_day) - Schedule calendar meetings\n",
    "3. check_calendar_availability(day) - Check available time slots for a given day\n",
    "4. manage_memory - Store any relevant information about contacts, actions, discussion, etc. in memory for future reference\n",
    "5. search_memory - Search for any relevant information that may have been stored in memory\n",
    "</ Tools >\n",
    "\n",
    "< Instructions >\n",
    "{instructions}\n",
    "</ Instructions >\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(state):\n",
    "    return [\n",
    "        {\n",
    "            \"role\" : \"system\",\n",
    "            \"content\" : agent_system_prompt_memory.format(\n",
    "                instructions=prompt_instructions[\"agent_instructions\"],\n",
    "                **profile\n",
    "            )\n",
    "        }\n",
    "    ] + state['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    write_email, \n",
    "    schedule_meeting,\n",
    "    check_calendar_availability,\n",
    "    manage_memory_tool,\n",
    "    search_memory_tool\n",
    "]\n",
    "\n",
    "# model = ChatOllama(model = \"MFDoom/deepseek-r1-tool-calling:8b\")\n",
    "    \n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "response_agent = create_react_agent(\n",
    "    model = model,\n",
    "    tools = tools,\n",
    "    prompt = create_prompt,\n",
    "    store = store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"langgraph_user_id\": \"lance2\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = response_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Jim is my friend\"}]},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Jim is my friend\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  manage_memory (call_usEX7rANjypyrrrx1aw2IK4q)\n",
      " Call ID: call_usEX7rANjypyrrrx1aw2IK4q\n",
      "  Args:\n",
      "    content: Jim is John's friend.\n",
      "    action: create\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: manage_memory\n",
      "\n",
      "created memory 201b1956-400f-4c5f-b13c-f6385fc548e5\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great! I've noted that Jim is your friend. If you need any further assistance, feel free to ask.\n"
     ]
    }
   ],
   "source": [
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = response_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"who is jim?\"}]},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "who is jim?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search_memory (call_TLTcH6kkdpdMtdW0WzHZmcbI)\n",
      " Call ID: call_TLTcH6kkdpdMtdW0WzHZmcbI\n",
      "  Args:\n",
      "    query: Jim\n",
      "    limit: 1\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: search_memory\n",
      "\n",
      "[{\"namespace\": [\"email_assistant\", \"lance2\", \"collection\"], \"key\": \"201b1956-400f-4c5f-b13c-f6385fc548e5\", \"value\": {\"content\": \"Jim is John's friend.\"}, \"created_at\": \"2025-03-18T14:03:13.016894+00:00\", \"updated_at\": \"2025-03-18T14:03:13.016894+00:00\", \"score\": 0.43422160353985967}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Jim is John's friend. If there's anything specific you need regarding Jim, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "for m in response[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('email_assistant', 'lance2', 'collection')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.list_namespaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Item(namespace=['email_assistant', 'lance2', 'collection'], key='201b1956-400f-4c5f-b13c-f6385fc548e5', value={'content': \"Jim is John's friend.\"}, created_at='2025-03-18T14:03:13.016894+00:00', updated_at='2025-03-18T14:03:13.016894+00:00', score=None)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.search(('email_assistant', 'lance2', 'collection'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the rest of the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    email_input: dict\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.types import Command\n",
    "from typing import Literal\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triage_route(state : State) -> Command[\n",
    "    Literal[\"response_agent\",  \"__end__\"]\n",
    "]:\n",
    "    author = state['email_input']['author']\n",
    "    to = state['email_input']['to']\n",
    "    subject = state['email_input']['subject']\n",
    "    email_thread = state['email_input']['email_thread']\n",
    "\n",
    "    system_prompt = triage_system_prompt.format(\n",
    "        full_name=profile[\"full_name\"],\n",
    "        name=profile[\"name\"],\n",
    "        user_profile_background=profile[\"user_profile_background\"],\n",
    "        triage_no=prompt_instructions[\"triage_rules\"][\"ignore\"],\n",
    "        triage_notify=prompt_instructions[\"triage_rules\"][\"notify\"],\n",
    "        triage_email=prompt_instructions[\"triage_rules\"][\"respond\"],\n",
    "        examples=None\n",
    "    )\n",
    "    \n",
    "    user_prompt = triage_user_prompt.format(\n",
    "        author=author, \n",
    "        to=to, \n",
    "        subject=subject, \n",
    "        email_thread=email_thread\n",
    "    )\n",
    "    \n",
    "    result = llm_router.invoke(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    if result.classification == \"respond\":\n",
    "        print(\"ðŸ“§ Classification: RESPOND - This email requires a response\")\n",
    "        goto = \"response_agent\"\n",
    "        update = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Respond to the email {state['email_input']}\",\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    elif result.classification == \"ignore\":\n",
    "        print(\"ðŸš« Classification: IGNORE - This email can be safely ignored\")\n",
    "        update = None\n",
    "        goto = END\n",
    "    elif result.classification == \"notify\":\n",
    "        # If real life, this would do something else\n",
    "        print(\"ðŸ”” Classification: NOTIFY - This email contains important information\")\n",
    "        update = None\n",
    "        goto = END\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid classification: {result.classification}\")\n",
    "    return Command(goto=goto, update=update)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
